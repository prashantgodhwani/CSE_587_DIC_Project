{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "*Inspired* and repurposed code by [ Lingjun (Ivan) Chen and Nuo (Nora) Xu[link text](https://)](https://sites.northwestern.edu/msia/2019/04/24/personalized-restaurant-recommender-system-using-hybrid-approach/)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "NGVwR-exCrfl"
      },
      "id": "NGVwR-exCrfl"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importing modules"
      ],
      "metadata": {
        "id": "f5ylAOK-cS0h"
      },
      "id": "f5ylAOK-cS0h"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "54283bb5"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from collections import Counter \n",
        "import math\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from lightfm import LightFM\n",
        "from lightfm.evaluation import precision_at_k,auc_score,reciprocal_rank\n",
        "import scipy\n",
        "import time\n",
        "import math\n",
        "from lightfm.data import Dataset"
      ],
      "id": "54283bb5"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "azqJKF0ophor"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "id": "azqJKF0ophor"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5cb92f69"
      },
      "outputs": [],
      "source": [
        "business=pd.read_csv('drive/MyDrive/business_final.csv')"
      ],
      "id": "5cb92f69"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "00dda267"
      },
      "outputs": [],
      "source": [
        "rest_review=pd.read_csv('drive/MyDrive/rest_review.csv')"
      ],
      "id": "00dda267"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fetching the categories of business"
      ],
      "metadata": {
        "id": "8djpPXvffYc7"
      },
      "id": "8djpPXvffYc7"
    },
    {
      "cell_type": "code",
      "source": [
        "category_frequency = [content for line in business['categories'] for content in line.split(\";\")]\n",
        "num_tags = [len(content) for line in business['categories'] for content in line.split(\";\")]\n",
        "sum(num_tags)"
      ],
      "metadata": {
        "id": "Ktwfdp9dBHC6"
      },
      "id": "Ktwfdp9dBHC6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Taking the top 60 categories as our features"
      ],
      "metadata": {
        "id": "rAPuBBhUXRUs"
      },
      "id": "rAPuBBhUXRUs"
    },
    {
      "cell_type": "code",
      "source": [
        "new_feature = Counter(category_frequency).most_common(60)\n",
        "print(new_feature)"
      ],
      "metadata": {
        "id": "tf8HyfNqg9R-"
      },
      "id": "tf8HyfNqg9R-",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## One hot encoding with chosen features and merging them with dataset"
      ],
      "metadata": {
        "id": "oDhPPU39Xa-T"
      },
      "id": "oDhPPU39Xa-T"
    },
    {
      "cell_type": "code",
      "source": [
        "new_feature = Counter(category_frequency).most_common(60)\n",
        "\n",
        "feature = pd.DataFrame()\n",
        "for ind, val in enumerate(new_feature[1:], start=1):\n",
        "  category, freq = val[0], val[1]\n",
        "  idf_score = math.log1p(len(business.business_id) / freq)\n",
        "  feature.loc[ind-1, ['Feature', 'Category_Score']] = category, idf_score"
      ],
      "metadata": {
        "id": "cwyELMdyCGGB"
      },
      "id": "cwyELMdyCGGB",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "business2 = business\n",
        "\n",
        "for index in range(feature.shape[0]):\n",
        "    f,idf = feature.loc[index,'Feature'],feature.loc[index,'Category_Score']\n",
        "    business2[f] = [1 / len(each_line) * idf if f in each_line else 0 \n",
        "                      for each_line in business2['categories'].str.split(';')]"
      ],
      "metadata": {
        "id": "XbEtg_OUDHiF"
      },
      "id": "XbEtg_OUDHiF",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c7bd1ee3"
      },
      "outputs": [],
      "source": [
        "rest_review.dtypes"
      ],
      "id": "c7bd1ee3"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "28ec9db5"
      },
      "outputs": [],
      "source": [
        "business2.dtypes"
      ],
      "id": "28ec9db5"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ce2feeb2"
      },
      "outputs": [],
      "source": [
        "rest_review=rest_review.merge(business2,on='business_id',how='inner')\n"
      ],
      "id": "ce2feeb2"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "89e577b4"
      },
      "outputs": [],
      "source": [
        "rest_review=rest_review.drop('Unnamed: 0_x',axis=1)"
      ],
      "id": "89e577b4"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading user dataset and extracting features"
      ],
      "metadata": {
        "id": "nKWoW6jcX0Dv"
      },
      "id": "nKWoW6jcX0Dv"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a0eda434"
      },
      "outputs": [],
      "source": [
        "user=pd.read_csv('drive/MyDrive/yelp_user.csv')\n",
        "user=user[['user_id','review_count','useful']]\n",
        "user=user.rename(columns={'review_count':'user_rc','useful':'user_useful'})\n",
        "rest_review=rest_review.merge(user,on='user_id',how='inner')\n",
        "rest_review.columns"
      ],
      "id": "a0eda434"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "77766c3c"
      },
      "outputs": [],
      "source": [
        "rest_review.columns# num_tags"
      ],
      "id": "77766c3c"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Normalizing columns "
      ],
      "metadata": {
        "id": "SRzTz241YN6G"
      },
      "id": "SRzTz241YN6G"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "84eeff3b"
      },
      "outputs": [],
      "source": [
        "rest_review.review_count = pd.Series([math.sqrt(x) for x in rest_review.review_count])\n",
        "rest_review.useful =  pd.Series([math.sqrt(x) for x in rest_review.useful])"
      ],
      "id": "84eeff3b"
    },
    {
      "cell_type": "code",
      "source": [
        "rest_review=rest_review.sample(frac=.01)\n",
        "business_id=rest_review.business_id.unique()\n",
        "business2=business2[business2['business_id'].isin(business_id)]"
      ],
      "metadata": {
        "id": "JjRgBrAU6yEa"
      },
      "id": "JjRgBrAU6yEa",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Created object dataset and fit it with user_id and business_id "
      ],
      "metadata": {
        "id": "H9aUHE6AYfFB"
      },
      "id": "H9aUHE6AYfFB"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BFJGPG9CYdzZ"
      },
      "id": "BFJGPG9CYdzZ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c53a34c1"
      },
      "outputs": [],
      "source": [
        "data_set = Dataset()\n",
        "data_set.fit(rest_review.user_id,business2.business_id)\n"
      ],
      "id": "c53a34c1"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fitting other features such as stars, review_count"
      ],
      "metadata": {
        "id": "F2H3t7rTZhbP"
      },
      "id": "F2H3t7rTZhbP"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a89fe92e"
      },
      "outputs": [],
      "source": [
        "data_set.fit_partial(items=business2.business_id,\n",
        "                    item_features=['stars','review_count'])\n"
      ],
      "id": "a89fe92e"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b723c4f6"
      },
      "outputs": [],
      "source": [
        "# creating a list of features from business table that include only categories we split and fitting them to our data_set.\n",
        "item_cols = [x for x in business2.columns[21:]]\n",
        "data_set.fit_partial(items = business2.business_id,item_features = item_cols)  "
      ],
      "id": "b723c4f6"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9b3fe65f"
      },
      "outputs": [],
      "source": [
        "item_cols"
      ],
      "id": "9b3fe65f"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3762005b"
      },
      "outputs": [],
      "source": [
        "rest_review.columns"
      ],
      "id": "3762005b"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "abaa5f3a"
      },
      "outputs": [],
      "source": [
        "# creating list of features from rest_review table and fitting them to the model\n",
        "user_1 = [x for x in rest_review.columns[29:]]\n",
        "user_1"
      ],
      "id": "abaa5f3a"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b19e33f3"
      },
      "outputs": [],
      "source": [
        "data_set.fit_partial(users=rest_review.user_id,\n",
        "                    user_features = user_1)\n"
      ],
      "id": "b19e33f3"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Created interaction sparse matrix from review table"
      ],
      "metadata": {
        "id": "v4iFQcb8Zy5Y"
      },
      "id": "v4iFQcb8Zy5Y"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9a384ab5"
      },
      "outputs": [],
      "source": [
        "(interactions, weights) = data_set.build_interactions([(x['user_id'],x['business_id'],x[['stars_x']]) for index,x in rest_review.iterrows()])\n",
        "print(repr(interactions))"
      ],
      "id": "9a384ab5"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "32663d1e"
      },
      "outputs": [],
      "source": [],
      "id": "32663d1e"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "52099601"
      },
      "outputs": [],
      "source": [
        "def compute_rmse(X_test, X_pred):\n",
        "    # Ref: https://github.com/ncu-dart/rdf/blob/master/rdf/utils.py\n",
        "    \n",
        "    sse = 0.\n",
        "    for i in range(len(X_test)):\n",
        "        sse += (X_test[i] - X_pred[i]) ** 2\n",
        "    \n",
        "    return (sse / len(X_test)) ** .5"
      ],
      "id": "52099601"
    },
    {
      "cell_type": "markdown",
      "source": [
        "created functions that bulids dictionaries which are used to user and item feature mapping and the values for the features are normalized to preserve the importance of features"
      ],
      "metadata": {
        "id": "BNBPkdkGZ8jH"
      },
      "id": "BNBPkdkGZ8jH"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YAKc3ajSZ7N6"
      },
      "id": "YAKc3ajSZ7N6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1724d99f"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "def item(df,item_cols,values):\n",
        "    output = {}\n",
        "    for col in item_cols:\n",
        "        output.update({col: df[col]})\n",
        "    sum_val = sum(float(value) for value in output.values()) # get sum of all the tfidf values\n",
        "    \n",
        "    if(sum_val == 0):\n",
        "        return output\n",
        "    else:\n",
        "      for key, value in output.items():\n",
        "        output[key] = value / sum_val # normalizing it to preserve the importance of all features\n",
        "    return output\n",
        "\n",
        "def user_dict(df,item_cols,values):\n",
        "    output = {}\n",
        "    for col in item_cols:\n",
        "        output.update({col: df[col]})\n",
        "    sum_val = sum(list(output.values())) # get sum of all the tfidf values\n",
        "    \n",
        "    if(sum_val == 0):\n",
        "        return output\n",
        "    else:\n",
        "        for key, value in output.items():\n",
        "          output[key] = value / sum_val # normalizing it to preserve the importance of all features\n",
        "    return output\n",
        "\n",
        "# get max of each column to regularize value to [0,1]\n",
        "star_max = business2.stars.max()\n",
        "max_item = business2.review_count.max()\n",
        "max_u_rc = rest_review.review_count.max()\n",
        "max_useful = rest_review.useful.max()\n",
        "\n",
        "# build item features\n",
        "item_features_data = []\n",
        "for index, x in business2.iterrows():\n",
        "    feature_dict = {\n",
        "        'stars': 0.8 * x['stars'] / star_max,\n",
        "        'review_count': 0.2 * x['review_count'] / max_item,\n",
        "    }\n",
        "    feature_dict.update(item(x, item_cols, [0.5 * x['stars'] / star_max, 0.5 * x['review_count'] / max_item]))\n",
        "    item_features_data.append((x['business_id'], feature_dict))\n",
        "item_features = data_set.build_item_features(tqdm(item_features_data, desc=\"Building item features\"))\n",
        "\n",
        "# build user features\n",
        "user_features_data = []\n",
        "for index, x in rest_review.iterrows():\n",
        "    feature_dict = {\n",
        "        'user_rc': 0.7 * x['user_rc'] / max_u_rc,\n",
        "        'user_useful': 0.3 * x['user_useful'] / max_useful,\n",
        "    }\n",
        "    feature_dict.update(user_dict(x, user_1, [0.7 * x['user_rc'] / max_u_rc, 0.3 * x['user_useful'] / max_useful]))\n",
        "    user_features_data.append((x['user_id'], feature_dict))\n",
        "user_features = data_set.build_user_features(tqdm(user_features_data, desc=\"Building user features\"))\n",
        "\n"
      ],
      "id": "1724d99f"
    },
    {
      "cell_type": "markdown",
      "source": [
        "split out interactions matrix created earlier into train and test with train having 80% and test set having 20%. "
      ],
      "metadata": {
        "id": "Kio4n9dSaYFf"
      },
      "id": "Kio4n9dSaYFf"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7b72826e"
      },
      "outputs": [],
      "source": [
        "seed = 69\n",
        "from lightfm.cross_validation import random_train_test_split\n",
        "train,test=random_train_test_split(interactions,test_percentage=0.2,random_state=np.random.RandomState(seed))\n",
        "test = test - train.multiply(test)"
      ],
      "id": "7b72826e"
    },
    {
      "cell_type": "markdown",
      "source": [
        "defined hyperparameters and applied grid search to our model to get the best parameters which get the best auc score"
      ],
      "metadata": {
        "id": "NrjWO12jcH4y"
      },
      "id": "NrjWO12jcH4y"
    },
    {
      "cell_type": "code",
      "source": [
        "from itertools import product\n",
        "NUM_THREADS = [5]\n",
        "NUM_COMPONENTS = [30, 50]\n",
        "LEARNING_RATE = [0.01,  0.1]\n",
        "NUM_EPOCHS = [10, 20]\n",
        "ITEM_ALPHA = [1e-5, 1e-6]\n",
        "loss=['warp','logistic']\n",
        "grid = product(NUM_THREADS, NUM_COMPONENTS, LEARNING_RATE, NUM_EPOCHS, ITEM_ALPHA,loss)\n",
        "def train_evaluate_model(train, test, user_features, item_features, num_threads, num_components, learning_rate, num_epochs, item_alpha,loss):\n",
        "    model = LightFM(loss=loss, item_alpha=item_alpha, random_state=seed, no_components=num_components,learning_rate=learning_rate)\n",
        "    model = model.fit(train, user_features=user_features, item_features=item_features, epochs=num_epochs, num_threads=num_threads)\n",
        "    test_precision = precision_at_k(model, test, train_interactions=train, item_features=item_features, user_features=user_features, k=5, num_threads=num_threads).mean()\n",
        "    test_auc = auc_score(model, test, item_features=item_features, user_features=user_features, num_threads=num_threads).mean()\n",
        "    return (num_threads, num_components, learning_rate, num_epochs, item_alpha, test_precision, test_auc,loss)\n",
        "\n",
        "results = []\n",
        "for params in grid:\n",
        "    num_threads, num_components, learning_rate, num_epochs, item_alpha,loss = params\n",
        "    result = train_evaluate_model(train, test, user_features, item_features, num_threads, num_components, learning_rate, num_epochs, item_alpha,loss)\n",
        "    results.append(result)\n",
        "    print(f\"num_threads={num_threads}, num_components={num_components}, learning_rate={learning_rate}, num_epochs={num_epochs}, item_alpha={item_alpha}, test_precision={result[5]:.4f}, test_auc={result[6]:.4f},best_func={loss}\")\n",
        "\n",
        "best_result = max(results, key=lambda x: x[6])\n",
        "print(f\"\\nBest hyperparameters: num_threads={best_result[0]}, num_components={best_result[1]}, learning_rate={best_result[2]}, num_epochs={best_result[3]}, item_alpha={best_result[4]}, test_precision={best_result[5]:.4f}, test_auc={best_result[6]:.4f},best_loss_func={best_result[7]}\")"
      ],
      "metadata": {
        "id": "RL0wFLQEH_ih"
      },
      "id": "RL0wFLQEH_ih",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Using our best hyperparameters got from grid search "
      ],
      "metadata": {
        "id": "-T7XHtOMckRy"
      },
      "id": "-T7XHtOMckRy"
    },
    {
      "cell_type": "code",
      "source": [
        "from lightfm.evaluation import  recall_at_k\n",
        "\n",
        "num_threads=5\n",
        "num_components=50\n",
        "learning_rate=0.1\n",
        "num_epochs=[5,10,15,20,25,30]\n",
        "item_alpha=1e-05\n",
        "test_scores=pd.DataFrame(columns=['AUC','precision','recall'])\n",
        "for i in num_epochs:\n",
        "\n",
        "  model = LightFM(loss='warp',item_alpha=item_alpha,random_state=69,no_components=num_components,learning_rate=learning_rate)\n",
        "  model = model.fit(train,user_features=user_features,item_features=item_features,epochs=i,num_threads=num_threads)\n",
        "  test_auc = auc_score(model, test,user_features=user_features,item_features=item_features,num_threads=num_threads).mean()\n",
        "  precision=precision_at_k(model, test,train_interactions=train,item_features=item_features,user_features=user_features, k=1,num_threads=num_threads).mean()\n",
        "\n",
        "  recall = recall_at_k(model, test,train_interactions=train,\n",
        "                            item_features=item_features, user_features=user_features, \n",
        "                            k=1, num_threads=num_threads).mean()\n",
        "  test_scores.loc[f'{i}']=[test_auc,precision,recall]\n",
        "  \n"
      ],
      "metadata": {
        "id": "UXFh6I2moeeW"
      },
      "id": "UXFh6I2moeeW",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Calculating auc score, precision and recall for every epoch"
      ],
      "metadata": {
        "id": "HfU7ou1gO9v3"
      },
      "id": "HfU7ou1gO9v3"
    },
    {
      "cell_type": "code",
      "source": [
        "test_scores\n"
      ],
      "metadata": {
        "id": "5oqmmFekTKxs"
      },
      "id": "5oqmmFekTKxs",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def recommend(model, train, data_meta, user_ids, k, name, mapping, tag=None, user_features=None, item_features=None, num_threads=2):\n",
        "    n_users, n_items = train.shape\n",
        "\n",
        "    recommendations = {}\n",
        "\n",
        "    for user_id in user_ids:\n",
        "        t_idx = {value: key for key, value in mapping.items()}\n",
        "        u_idx = train.getrow(user_id).indices\n",
        "\n",
        "        known_positives = data_meta.loc[u_idx, name]\n",
        "        if tag is not None:\n",
        "            known_tags = data_meta.loc[u_idx, tag]\n",
        "\n",
        "        scores = model.predict(user_id, np.arange(n_items), user_features=user_features, item_features=item_features, num_threads=num_threads)\n",
        "        item_ids = np.argsort(-scores)[:k]\n",
        "        top_items = data_meta.iloc[item_ids]['name']\n",
        "\n",
        "        recommendations[user_id] = top_items\n",
        "\n",
        "    return recommendations\n"
      ],
      "metadata": {
        "id": "p0BWRma3DXNg"
      },
      "id": "p0BWRma3DXNg",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "user_index=list(set(rf.get_user_index(test)))\n",
        "a=recommend(model,train,business2,[49],5,'name',mapping=data_set.mapping()[2],tag='categories',\n",
        "                              user_features = user_features,item_features=item_features).values()\n",
        "pd.DataFrame(a).transpose()"
      ],
      "metadata": {
        "id": "f1rlRZzKDc_-"
      },
      "id": "f1rlRZzKDc_-",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "plt.plot(test_scores['AUC'])\n",
        "plt.title('AUC')\n",
        "plt.xlabel('Auc')\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "y-bQxjECq6Dz"
      },
      "id": "y-bQxjECq6Dz",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(test_scores['precision'])\n",
        "plt.title('precision')\n",
        "plt.xlabel('precision')"
      ],
      "metadata": {
        "id": "gJ0HbUh1tXBp"
      },
      "id": "gJ0HbUh1tXBp",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(test_scores['recall'])\n",
        "plt.title('recall')\n",
        "plt.xlabel('recall')"
      ],
      "metadata": {
        "id": "nHyjdgv8tf5X"
      },
      "id": "nHyjdgv8tf5X",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "P9q_Zvp8o5ss"
      },
      "id": "P9q_Zvp8o5ss",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "data = pd.DataFrame({\n",
        "    'test_precision': [0.0036, 0.0003, 0.0036, 0.0003, 0.0033, 0.0003, 0.0037, 0.0003, 0.0070, 0.0003, 0.0071, 0.0003, 0.0106, 0.0003, 0.0120, 0.0003, 0.0037, 0.0003, 0.0037, 0.0003, 0.0039, 0.0003, 0.0040, 0.0003],\n",
        "    'test_auc': [0.6398, 0.5757, 0.6391, 0.5757, 0.7286, 0.5755, 0.9276, 0.9755, 0.7737, 0.5750, 0.7788, 0.9751, 0.8041, 0.9749, 0.9069, 0.9751, 0.9327, 0.5759, 0.9321, 0.5759, 0.9242, 0.5756, 0.6223, 0.5756],\n",
        "    'loss_func': ['warp', 'logistic', 'warp', 'logistic', 'warp', 'logistic', 'warp', 'logistic', 'warp', 'logistic', 'warp', 'logistic', 'warp', 'logistic', 'warp', 'logistic', 'warp', 'logistic', 'warp', 'logistic', 'warp', 'logistic', 'warp', 'logistic']\n",
        "})\n",
        "\n",
        "heatmap_data = pd.pivot_table(data, values=['test_precision', 'test_auc'], index='loss_func')\n",
        "\n",
        "sns.heatmap(heatmap_data, cmap='YlGnBu', annot=True, annot_kws={\"size\": 10})"
      ],
      "metadata": {
        "id": "JXVC3Fy72EJ0"
      },
      "id": "JXVC3Fy72EJ0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "b8n2evre0E4m"
      },
      "id": "b8n2evre0E4m",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KVQCFn5v9Hwi"
      },
      "id": "KVQCFn5v9Hwi",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "private_outputs": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}